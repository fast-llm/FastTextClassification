# 二分类任务的超参数配置文件
# 训练配置
training:
  lang: 'cn'                                          # embedding 语言
  use_word: false                                     # 
  epochs: 50                                          # 训练的总周期数
  require_improvement: 1000                           # 早停的步数
  per_device_train_batch_size: 8                     # 每批训练的样本数
  per_device_eval_batch_size: 10                      # 每批测试的样本数
  update_all_layers: true                             # 更新预训练权重
  lr_scheduler_type: "cosine"                         # linear,cosine,polynomial,constant...
  learning_rate: 0.01                                 # 优化器的学习率
  warmup_steps: 20                                    # 学习率预热步数,两个只能有一个大于0,否则步数覆盖
  warmup_ratio: 0.1                                   # 学习率预热比例
  dropout_rate: 0.1                                   # Dropout比率，用于防止过拟合
  threshold: 0.5                                      # 计算准确率的阈值
  activation: "GELU"                                  # 激活函数
  seed: 42                                            # 随机种子，用于确保实验的可复现性

# 优化器配置
optimizer_settings:
  loss_fn: "CrossEntropyLoss"                         # CrossEntropyLoss, BCELoss,NLLLoss, 已经经过softmax就用BCE loss 损失函数
  optimizer_type: "SGD"                               # 优化器类型
  # weight_init_method: "xavier_uniform"              # 优化器的权重初始化方法
  weight_decay: 0.0                                   # 权重衰减
  momentum: 0.9                                       # SGD优化器的动量,0.9左右是最好的
  adam_epsilon: 1e-8                                  # Adam或AdamW优化器的epsilon值
  adam_beta1: 0.1                                     # Adam或AdamW优化器的beta1值
  adam_beta2: 0.999                                   # Adam或AdamW优化器的beta2值
  initial_accumulator_value: 0.1                      # Adagrad优化器的初始累加器值
  lr_decay: 0.1                                       # Adagrad学习率衰减
  power: 0.9                                          # 学习率多项式衰减的幂
  max_grad_norm: 5.0                                  # 梯度剪裁的最大梯度范数
  gradient_accumulation_steps: 1                      # 梯度累积步骤

# 模型结构参数
model_parameters:
  num_classes: 2                                      # 分类问题的类别数
  mlp_layers:
    - layer_type: "Dense"                             # 层的类型
      size: 1024                                       # 第一层的大小
      activation: "GELU"                              # 第一层的激活函数
      dropout: 0.2                                    # 第一层的Dropout率
    - layer_type: "Dense"                             # 层的类型
      size: 256                                       # 第二层的大小
      activation: "GELU"                              # 第二层的激活函数
      dropout: 0.2                                    # 第二层的Dropout率

# 超参数搜索配置
hyper_params:
  enable_search: false                              # 是否启用超参数搜索
  search_strategy: "random"                         # 超参数搜索策略
  search_trials: 10                                 # 超参数搜索的试验次数
  search_metric: "loss"                         # 超参数搜索的评分指标
  gamma: 0.25                                      # 超参数搜索的gamma值
  random_state: 42                                 # 超参数搜索的随机种子
  optimizer_options: ["Adam", "AdamW", "SGD"]                  # 优化器的可选类型
  learning_rate_bounds: [1e-5, 1e-3]                  # 学习率的搜索范围
  batch_size_options: [16, 32, 64]                    # 批量大小的可选值
  regularization_strengths: [0, 1e-4, 1e-3]                     # L2正则化强度的可选值
  dropout_rates: [0.3, 0.5, 0.7]                                # Dropout率的可选范围
  activation_functions: ["ReLU", "LeakyReLU", "ELU", "GELU"]            # 激活函数的可选列表
  weight_initialization: ["xavier_uniform", "xavier_normal", "kaiming_uniform", "kaiming_normal"]  # 权重初始化策略的可选列表

# 数据集路径
data:
  max_samples: None               # 可以指定要使用的样本数量，如果为None，则使用所有可用样本
  processing_num_workers: 1       # 预处理数据的worker
  streaming: false                # 指定是否使用延迟加载，延迟加载适用于大数据集，以避免一次性加载到内存
  train_file: "train.txt"         # 训练集
  val_file: "val.txt"             # 验证集
  test_file: "test.txt"           # 测试机
  class_file: "class.txt"         # 类别表
  vocab_file: "vocab.txt"         # 自定义词汇表
  SEP: "\t"                       # 分割符号
  cutoff_len: 768                 # 截断长度
  do_lower_case: false            # 是否将输入文本转换为小写
  multi_class: true              # 是否是多类分类
  multi_label: false               # 是否是多标签分类

# 输出目录配置
output:
  log_dir: "log"
  logging_steps: 5              # 日志记录的步数
  eval_steps: 50                # 评估的步数
  eval_metric: "accuracy"       # 评估的指标
  save_steps: 1000              # 模型保存的步数
  save_total_limit: 5           # 保存的模型数量

early_stopping:
  enable: false
  patience: 3
  early_stop_metric: "eval_loss"
  delta: 0.0

# TensorBoard配置
tensor_board:
  enable: false
  tensorboard_dir: null
  use_tensorboard: false

# 权重与偏差（Wandb）配置
wandb:
  wandb_project: null
  wandb_kwargs: {}
  wandb_logging: false